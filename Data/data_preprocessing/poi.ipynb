{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb6e489b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 categories:\n",
      " restaurant          567\n",
      "fast_food           285\n",
      "cafe                245\n",
      "hotel               201\n",
      "clothes             182\n",
      "gallery             117\n",
      "bank                115\n",
      "bicycle_rental       90\n",
      "bar                  72\n",
      "jewelry              70\n",
      "artwork              70\n",
      "theatre              60\n",
      "pub                  58\n",
      "gift                 57\n",
      "place_of_worship     46\n",
      "shoes                41\n",
      "attraction           38\n",
      "convenience          37\n",
      "beauty               32\n",
      "hairdresser          31\n",
      "Name: category, dtype: int64\n",
      "✅ Cleaned and enriched dataset saved as cleaned_pois_for_ml_ready.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load data\n",
    "df = pd.read_csv(\"all_pois_combined(13places_around).csv\", low_memory=False)\n",
    "\n",
    "# Step 2: Keep essential columns\n",
    "columns_to_keep = [\n",
    "    \"location_name\", \"id\", \"type\", \"lat\", \"lon\", \"name\",\n",
    "    \"amenity\", \"tourism\", \"leisure\", \"shop\",\n",
    "    \n",
    "]\n",
    "df_cleaned = df[columns_to_keep].copy()\n",
    "\n",
    "# Step 3: Remove POIs without any category info\n",
    "df_cleaned = df_cleaned.dropna(subset=[\"amenity\", \"tourism\", \"leisure\", \"shop\"], how=\"all\")\n",
    "\n",
    "# Step 4: Create unified 'category' field\n",
    "def merge_category(row):\n",
    "    for col in [\"amenity\", \"tourism\", \"leisure\", \"shop\"]:\n",
    "        if pd.notnull(row[col]):\n",
    "            return row[col]\n",
    "    return \"unknown\"\n",
    "\n",
    "df_cleaned[\"category\"] = df_cleaned.apply(merge_category, axis=1)\n",
    "\n",
    "# Step 5: Drop rows with missing name or coordinates\n",
    "df_cleaned = df_cleaned.dropna(subset=[\"name\", \"lat\", \"lon\"])\n",
    "\n",
    "# Step 6: Drop duplicate rows\n",
    "df_cleaned = df_cleaned.drop_duplicates(subset=[\"name\", \"lat\", \"lon\"])\n",
    "\n",
    "# Step 7: Normalize the 'category' field (lowercase, underscores)\n",
    "df_cleaned[\"category\"] = df_cleaned[\"category\"].str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "# Step 8: Add binary feature: is_tourist_spot\n",
    "tourist_keywords = [\n",
    "    \"museum\", \"artwork\", \"attraction\", \"viewpoint\", \"zoo\", \"theme_park\", \"aquarium\",\n",
    "    \"memorial\", \"castle\", \"monument\", \"historic\", \"heritage\"\n",
    "]\n",
    "df_cleaned[\"is_tourist_spot\"] = df_cleaned[\"category\"].apply(\n",
    "    lambda x: int(any(keyword in x for keyword in tourist_keywords))\n",
    ")\n",
    "\n",
    "# Optional Step 9: Filter out 'unknown' category rows if not needed\n",
    "df_cleaned = df_cleaned[df_cleaned[\"category\"] != \"unknown\"].copy()\n",
    "\n",
    "# Step 10: Reset index and check top categories\n",
    "df_cleaned.reset_index(drop=True, inplace=True)\n",
    "print(\"Top 20 categories:\\n\", df_cleaned[\"category\"].value_counts().head(20))\n",
    "\n",
    "# Step 11: Save cleaned dataset\n",
    "df_cleaned.to_csv(\"cleaned_pois_for_ml_ready.csv\", index=False)\n",
    "print(\"✅ Cleaned and enriched dataset saved as cleaned_pois_for_ml_ready.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp47350py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
